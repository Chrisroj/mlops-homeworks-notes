{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c63ed32-0951-4385-a360-22416d6dc8f9",
   "metadata": {},
   "source": [
    "# MlOps Notes\n",
    "\n",
    "1. [Module 1: Introduction](#module1)\n",
    "\n",
    "    1.1 [Introduction to MLOps](#intro)\n",
    "    \n",
    "    1.2 [Environment preparation](#environment)\n",
    "    \n",
    "      - 1.2.1 [VM Instance in GCP](#gcp)\n",
    "      \n",
    "      - 1.2.1 [Install Dependencies](#dependencies)\n",
    "      \n",
    "    1.3 [Course Overview](#overview)\n",
    "    \n",
    "    1.4 [MLOps Maturity Model](#maturity)\n",
    "\n",
    "2. [Module 2: Experiment tracking and model management](#module2)\n",
    "3. [Module 3: Orchestration and ML Pipelines](#module3)\n",
    "\n",
    "    3.1 [Negative engineering and workflow orchestration](#negative-and-orchestration)\n",
    "    \n",
    "    3.2 [Introduction to Prefect 2.0](#prefect)\n",
    "\n",
    "    3.3 [First Prefect flow and basics](#prefect-flow)\n",
    "    \n",
    "    - 3.3.1 [Adding a  Prefect flow](#flow)\n",
    "    \n",
    "    - 3.3.2 [Adding a Prefect task](#task)\n",
    "    \n",
    "    - 3.3.3 [Sequential Task Running](#seq)\n",
    "    \n",
    "    - 3.3.4 [Logs in Prefect](#logs)\n",
    "    \n",
    "    - 3.3.5 [Prefect UI](#ui)\n",
    "    \n",
    "    - 3.3.6 [Parameter Type Validation](#val)\n",
    "    \n",
    "    3.4 [Remote Prefect Orion Deployment](#remote)\n",
    "\n",
    "    - 3.4.1 [Remote Prefect Orion](#orion)\n",
    "    \n",
    "    - 3.4.2 [Using Prefect Cloud](#cloud)\n",
    "    \n",
    "    - 3.4.3 [Defining Storage for Prefect localy](#storage-localy)\n",
    "    \n",
    "    - 3.4.4 [Defining Storage for Prefect in AWS S3](#storage-aws)\n",
    "\n",
    "    3.5 [Deployment of Prefect flow](#deploy-prefect)\n",
    "    \n",
    "    - 3.5.1 [Deployment](#deploy)\n",
    "    \n",
    "    - 3.5.2 [CronSchedule](#schedule)\n",
    "    \n",
    "    - 3.5.3 [Work Queues](#queue)\n",
    "    \n",
    "    - 3.5.4 [Adding a Local Agent](#agent)\n",
    "    \n",
    "\n",
    "12. [References](#references)\n",
    "\n",
    "This notes are about [MLOps Zoomcamp](https://github.com/DataTalksClub/mlops-zoomcamp)\n",
    "\n",
    "# Module 1: Introduction <a name=\"module1\"></a>\n",
    "\n",
    "[Source](https://github.com/DataTalksClub/mlops-zoomcamp/tree/main/01-intro)\n",
    "\n",
    "## Introduction to MLOps <a name=\"intro\"></a>\n",
    "\n",
    "[Video source](https://youtu.be/s0uaFZSzwfI?list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK)\n",
    "\n",
    "***MLOps*** is a _set of best practices_ for bringing Machine Learning to production.\n",
    "\n",
    "Machine Learning projects can be simpplified to just 3 steps:\n",
    "\n",
    "1. ***Design*** - is ML the right tool for solving our problem?\n",
    "   * _We want to predict the duration of a taxi trip. Do we need to use ML or can we used a simpler rule-based model?_\n",
    "2. ***Train*** - if we do need ML, then we train and evaluate the best model.\n",
    "3. ***Operate*** - model deployment, management and monitoring.\n",
    "\n",
    "MLOps is helpful in all 3 stages.\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "\n",
    "## Environment preparation <a name=\"environment\"></a>\n",
    "\n",
    "[Video source](https://www.youtube.com/watch?v=IXSiYkP23zo&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK)\n",
    "\n",
    "\n",
    "You may check the link above to watch the video in order to learn how to set up a Linux VM instance in Amazon Web Services.\n",
    "You can prepare your environment in your local machine too, but in our case we are going to set up a VM instance in GCP.\n",
    "\n",
    "\n",
    "### VM Instance in GCP <a name=\"gcp\"></a>\n",
    "\n",
    "Before to create an instance in GCP we need to generate a SSH key(if you want to know what SSH is you can check this [video](https://www.youtube.com/watch?v=RMS5zBYQIqA)). In your local console(in my case in Git Bash in windows) follow:\n",
    "\n",
    "You can watch this [video](https://www.youtube.com/watch?v=ae-CV2KfoN0) or follow the next instructions.\n",
    "\n",
    "1. **Create SSH keys:**\n",
    "\n",
    "    Create(if you don't have) and go to ```~/.ssh``` directory and type:\n",
    "\n",
    "```bash\n",
    "ssh-keygen -t rsa -f KEY_FILENAME -C USER -b 2048\n",
    "```\n",
    "    Example:\n",
    "\n",
    "```bash\n",
    "ssh-keygen -t rsa -f gcp_ssh -C w10 -b 2048\n",
    "```\n",
    "\n",
    "[Source](https://cloud.google.com/compute/docs/connect/create-ssh-keys)\n",
    "\n",
    "2. **Put this SSH key in GCP:**\n",
    "    \n",
    "    1. Copy public key:\n",
    "    \n",
    "        ```bash\n",
    "        cat KEY_FILENAME.pub\n",
    "        ```\n",
    "        Example:\n",
    "        ```bash\n",
    "        cat gcp_ssh.pub\n",
    "        ```\n",
    "    2. In Cloud console go to **Metadata** -> **EDIT** -> **SSH keys** -> **Add item** -> **Paste public key** -> **Save**\n",
    "    \n",
    "_[Source](https://cloud.google.com/compute/docs/connect/add-ssh-keys)_\n",
    "    \n",
    "3. **Create VM Instance:**\n",
    "\n",
    "    In Cloud console go to **Compute Engine** -> **VM Instances** -> **Create Instance** config the VM as:\n",
    "    * name: `mlops-zoomcamp-vm`\n",
    "    * region: `us-west4 (Las Vegas)`, zone: `us-west4-b`\n",
    "    * serie: `E2`, type: `e2-standard-4`\n",
    "    * boot disk image: `Ubuntu 22.04 LTS` boot disk type: `balanced persistent disk` size(gb): `30`\n",
    "    \n",
    "4. **Connect to VM Instance:** \n",
    "\n",
    "    Go to ```~./.ssh``` directory and locate the ```config``` type ```nano ~/.ssh/config```copy and paste:\n",
    "\n",
    "```bash\n",
    "Host mlops-zoomcamp-vm\n",
    "    HostName EXTERNAL_IP\n",
    "    User USER\n",
    "    IdentityFile KEY_FILENAME directory\n",
    "    LocalForward PORT_1 IP:PORT_1\n",
    "    LocalForward PORT_2 IP:PORT_2\n",
    "    LocalForward PORT_3 IP:PORT_3\n",
    "```\n",
    "  \n",
    "    Example:\n",
    "\n",
    "```bash\n",
    "Host mlops-zoomcamp-vm\n",
    "    HostName 34.125.197.156\n",
    "    User w10\n",
    "    IdentityFile C:\\Users\\w10\\.ssh\\gcp_ssh\n",
    "    LocalForward 8888 localhost:8888\n",
    "    LocalForward 5000 127.0.0.1:5000\n",
    "    LocalForward 4200 0.0.0.0:4200\n",
    "```\n",
    "\n",
    "\n",
    "    The EXTERNAL_IP can change every time you power one the VM. \n",
    "Now you can type `ssh mlops-zoomcamp-vm` in your console and you'll get connected to the VM.\n",
    "\n",
    "**Note0**: In step 4 in ```config``` file the last two lines are to forward multiple port through the same host, in this case \n",
    "```LocalForward 8888 localhost:8888``` is for jupyter, ```LocalForward 5000 127.0.0.1:5000``` is for MLflow and ```LocalForward 4200 0.0.0.0:4200``` is for Prefect. You can add more LocalForward if you want.\n",
    "\n",
    "**Note1**: Don't forget to power off the VM after your work you can use ```sudo poweroff```. \n",
    "\n",
    "**Note2**: if you get the next warning:\n",
    "```bash\n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "```\n",
    "Then copy and paste the EXTERNAL_IP of your VM and type:\n",
    "\n",
    "```bash\n",
    "ssh-keygen -R \"34.125.105.3\"\n",
    "```\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "### Install Dependencies <a name=\"dependencies\"></a>\n",
    "\n",
    "Now we need to install the next dependencies(you can update the links for Anaconda and Docker Compose):\n",
    "\n",
    "- **Install Anaconda**:\n",
    "\n",
    "```bash\n",
    "cd ~\n",
    "wget https://repo.anaconda.com/archive/Anaconda3-2022.05-Linux-x86_64.sh\n",
    "bash Anaconda3-2022.05-Linux-x86_64.sh\n",
    "```\n",
    "\n",
    "- **Install Docker**:\n",
    "\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt install docker.io\n",
    "```\n",
    "\n",
    "- **Install Docker Compose**\n",
    "\n",
    "```bash\n",
    "mkdir soft\n",
    "cd soft/\n",
    "wget https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-linux-x86_64 -O docker-compose\n",
    "chmod +x docker-compose\n",
    "```\n",
    "\n",
    "- **Modified PATH Varibles**\n",
    "\n",
    "\n",
    "   Type ```nano .bashrc```, copy and paste the next at the end of the `.bashrc` file\n",
    "\n",
    "```bash\n",
    "export PATH=\"${HOME}/soft:${PATH}\"\n",
    "```\n",
    "\n",
    "Type `source .bashrc`, now everything that is in `/soft` directory will be in the PATH then you can execute it everywhere.\n",
    "\n",
    "- **Add current user to docker group**\n",
    "\n",
    "```bash\n",
    "sudo usermod -aG docker $USER\n",
    "logout\n",
    "```\n",
    "\n",
    "Then logback to the VM.\n",
    "\n",
    "- **Verify Installation**\n",
    "\n",
    "```bash\n",
    "which python\n",
    "# /home/w10/anaconda3/bin/python\n",
    "\n",
    "which docker\n",
    "# /usr/bin/docker\n",
    "\n",
    "which docker-compose\n",
    "# /home/w10/soft/docker-compose\n",
    "\n",
    "docker run hello-world\n",
    "```\n",
    "\n",
    "- **Run Jupyter Notebook**\n",
    "\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "\n",
    "## Course Overview <a name=\"overview\"></a>\n",
    "\n",
    "[Video source](https://www.youtube.com/watch?v=teP9KWkP6SM&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=6)\n",
    "\n",
    "When data scientists experiment with Jupyter Notebooks for creating models, they often don't follow best practices and are often unstructured due to the nature of experimentation: cells are re-run with slightly different values and previous results may be lost, or the cell execution order may be inconsistent, for example.\n",
    "\n",
    "***Module 2*** covers ***experiment tracking***: by using tools such as [MLflow](https://mlflow.org/) we will create ***experiment trackers*** (such as the history of cells that we've rerun multiple times) and ***model registries*** (for storing the models we've created during the experiments), instead of relying on our memory or janky setups such as external spreadsheets or convoluted naming schemes for our files.\n",
    "\n",
    "***Module 3*** covers ***orchestration and ML pipelines***: by using tools such as [Prefect](https://www.prefect.io/) and [Kubeflow](https://www.kubeflow.org/) we can break down our notebooks into separate identifyable steps and connect them in order to create a ***ML pipeline*** which we can parametrize with the data and models we want and easily execute.\n",
    "\n",
    "![asda](./Images/Module1/ML-pipeline.PNG)\n",
    "\n",
    "***Module 4*** covers ***serving the models***: we will learn how to deploy models in different ways.\n",
    "\n",
    "***Module 5*** covers ***model monitoring***: we will see how to check whether our model is performing fine or not and how to generate alers to warn us of performance drops and failures, and even automate retraining and redeploying models without human input.\n",
    "\n",
    "***Module 6*** covers ***best practices***, such as how to properly maintain and package code, how to deploy successfully, etc.\n",
    "\n",
    "***Module 7*** covers ***processes***: we will see how to properly communicate between all the stakeholders of a ML project (scientists, engineers, etc) and how to work together.\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "\n",
    "## MLOps Maturity Model <a name=\"maturity\"></a>\n",
    "\n",
    "[Video Source](https://www.youtube.com/watch?v=XwTH8BDGzYk&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=7)\n",
    "\n",
    "[Table Source](https://docs.microsoft.com/en-us/azure/architecture/example-scenario/mlops/mlops-maturity-model)\n",
    "\n",
    "A framework for classifying different levels of MLOps maturity is listed below:\n",
    "\n",
    "\n",
    "| Lvl |              | Overview | Use Case | \n",
    "|----:|--------------|----------|----------|  \n",
    "| 0️⃣  | **No MLOps** | <ul><li>ML process highly manual</li><li>poor cooperation</li><li>lack of standards, success depends on an individual's expertise</li> </ul> | <ul><li>proof of concept (PoC)</li><li>academic project</li></ul> |\n",
    "| 1️⃣  | **DevOps but no MLOps** | <ul><li>ML training is most often manual </li><li>software engineers might help with the deployment</li><li>automated tests and releases</li> </ul> | <ul><li>bringing PoC to production</li></ul> |\n",
    "| 2️⃣  | **Automated Training** | <ul><li>ML experiment results are centrally tracked </li><li>training code and models are version controlled</li><li>deployment is handled by software engineers</li> </ul> | <ul><li>maintaining 2-3+ ML models</li></ul> |\n",
    "| 3️⃣  | **Automated Model Deployment** | <ul><li>releases are managed by an automated CI/CD pipeline</li><li>close cooperation between data and software engineers</li><li>performance of the deployed model is monitored, A/B tests for model selection are used</li></ul> | <ul><li>business-critical ML services</li></ul> |\n",
    "| 4️⃣  | **Full MLOps Automated Operations** | <ul><li>clearly defined metrics for model monitoring</li><li>automatic retraining triggered when passing a model metric's threshold</li> </ul>  | <ul><li>use only when a favorable trade-off between implementation cost and increase in efficiency is likely</li><li>retraining is needed often and is repetitive (has potential for automation)</li></ul> |\n",
    "\n",
    "Be aware that not every project or even every part of a project needs to have the highest maturity level possible because it could exceed the project's resource budget. **Pragmatism is key**.\n",
    "\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "# Module 3: Orchestration and ML Pipelines <a name=\"module3\"></a>\n",
    "\n",
    "## Negative engineering and workflow orchestration <a name=\"negative-and-orchestration\"></a>\n",
    "\n",
    "[Video Source](https://www.youtube.com/watch?v=eKzCjNXoCTc&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=20)\n",
    "\n",
    "**Workflow Orchestration**\n",
    "\n",
    "It's a set of tools that schedule and monitor work that you want to accomplish. Ex: Scheduling ML models training\n",
    "\n",
    "Exmaple pipeline: \n",
    "```\n",
    "PostgresQL -> Parquet -> Pandas -> Sklearn -> mlflow\n",
    "                                      ↳ Rest API ↳ Flask (If deploying)\n",
    "```\n",
    "Random Points of Failure can occur in the pipeline. The goal of the workflow orchestration is to minimize the errors and fail\n",
    "gracefully.\n",
    "\n",
    "In more interconnected pipelines (Different pipelines interconnected) failure points are more common.\n",
    "\n",
    "**Negative Engineering**\n",
    "\n",
    "90% of engineering time is spent on:\n",
    "+ Retries when APIs go down\n",
    "+ Malformed data\n",
    "+ Notifications\n",
    "+ Observability into Failure\n",
    "+ Conditional Failure Logic\n",
    "+ Timeouts\n",
    "\n",
    "Prefect's goal is to reduce this time to increase productivity; The goal is to reduce the time spent on Negative Engineering.\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "## Introducting Prefect <a name=\"prefect\"></a>\n",
    "\n",
    "[Video Source](https://www.youtube.com/watch?v=Yb6NJwI7bXw&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=21)\n",
    "\n",
    "Open Source Workflow Orchestration Framework for eliminating Negative Engineering:\n",
    "+ Open Source\n",
    "+ Python-based\n",
    "+ Modern data stack\n",
    "+ Native Dask integration\n",
    "+ Very active Community\n",
    "+ Prefect Cloud/Prefect Server -> Cloud is hosted by Prefect, Server Self-hosted.\n",
    "\n",
    "Prefect Orion (aka Prefect 2.0) is an overwhole on Prefect 1.0; No backwards/forwards compatibility. **It's in Beta**\n",
    "\n",
    "**Current state of Prefect**:\n",
    "\n",
    "+ Prefect Core (1.0)\n",
    "+ Prefect Orion (2.0 beta)\n",
    "+ Prefect uses Decorators to wrap the code.\n",
    "\n",
    "**Deploying Notebooks**:\n",
    "\n",
    "We don't deploy notebooks, and if deployed they're deployed as a single step. Notebooks are thus refactored into scripts for\n",
    "deployment\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## First Prefect flow and basics <a name=\"prefect-flow\"></a>\n",
    "\n",
    "[Video Source](https://www.youtube.com/watch?v=MCFpURG506w&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=22)\n",
    "\n",
    "### Adding a  Prefect flow <a name=\"flow\"></a>\n",
    "\n",
    "We implement Prefect in our code by wrapping the workflow function (which fetches the data, preprocesses it, trains the model...etc) with a `@flow` decorator as:\n",
    "\n",
    "```python\n",
    "from prefect import flow\n",
    "\n",
    "@flow\n",
    "def main():\n",
    "  ...\n",
    "```\n",
    "This enables extra logging. \n",
    "\n",
    "The main function is what is usually put in a `if \"__name\"\" == \"__main__\":` bloc wrapped as a function. (Name doesn't matter)\n",
    "\n",
    "Multiple Flows can be put in the same file.\n",
    "\n",
    "### Adding a Prefect task <a name=\"task\"></a>\n",
    "\n",
    "(Note: Prefect 1.0/2.0 difference: In 2.0 we can mix and match between normal functions and `@task` functions.\n",
    "In 1.0 we couldn't)\n",
    "\n",
    "We can then add tasks by using the `@task` decorator around our task function (example: preprocessing, training... etc):\n",
    "```python\n",
    "@task\n",
    "def train_model(X,y):\n",
    "  ...\n",
    "```\n",
    "The output of a function wrapped around a `@task` is a `PrefectFuture` object. If we're mixing and matching normal functions \n",
    "with `@task`ed functions we need to get the result of the function by calling `.result()` on the `PrefectFuture`. For example:\n",
    "```python\n",
    "from prefect import flow, task\n",
    "\n",
    "X_train, X_val, y_train, y_val, dv = add_features(train_path, val_path).result()\n",
    "```\n",
    "Otherwise we'll just get the `PrefectFuture` object (likely with a crash).\n",
    "\n",
    "Adding a task enables further logging.\n",
    "\n",
    "Tasks can also have parameters like caching and retries.\n",
    "\n",
    "### Sequential Task Running <a name=\"seq\"></a>\n",
    "If tasks don't depend on each other, Prefect will run the tasks asynchronously by default. This can't be handled by MLflow, so\n",
    "in order to force sequential task running we add a parameter to the `@flow` decorator:\n",
    "\n",
    "```python\n",
    "from prefect import flow, task\n",
    "from prefect.task_runners import SequentialTaskRunner\n",
    "@flow(task_runner=SequentialTaskRunner())\n",
    "def main():\n",
    "  ...\n",
    "```\n",
    "\n",
    "### Logs <a name=\"logs\"></a>\n",
    "\n",
    "If you have prints inside a task you could'nt see in the Prefect UI, you should remove the prints and use ```get_run_logger``` instead.\n",
    "\n",
    "```python\n",
    "from prefect import flow, task, get_run_logger\n",
    "\n",
    "@task\n",
    "def train_model(X, y):\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"My log\")\n",
    "    ...\n",
    "```\n",
    "\n",
    "### Prefect UI <a name=\"ui\"></a>\n",
    "\n",
    "We can open the Prefect UI (In Orion) using `prefect orion start` to spin up a localhost instance.\n",
    "The UI contains information and logs of varying detail about each flow run and where errors may have occured in the process\n",
    "as well as error Stacktraces and task flows.\n",
    "\n",
    "### Parameter Type Validation <a name=\"val\"></a>\n",
    "If an Orion flow receives a bad parameter type, instead of running the flow and inevitably failing, it will instead not run the flow at all and output a failed run to save compute time.\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Remote Prefect Orion Deployment <a name=\"remote\"></a>\n",
    "\n",
    "[Video Source](https://www.youtube.com/watch?v=ComkSIAB0k4&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=23)\n",
    "\n",
    "### Remote Prefect Orion<a name=\"orion\"></a>\n",
    "\n",
    "In order to remotely deploy Prefect. The remote VM needs some ports open:\n",
    "\n",
    "| Connection Type | Port  |\n",
    "|-----------------|-------|\n",
    "| HTTP            | [80]  |\n",
    "| HTTPS           | [443] |\n",
    "| TCP             | 4200  |\n",
    "| UDP             | 4200  |\n",
    "\n",
    "[How to do it in AWS](https://vanchiv.com/open-port-on-aws-ec2-instance/)\n",
    "[How to do it in GCP](https://www.howtogeek.com/devops/how-to-open-firewall-ports-on-a-gcp-compute-engine-instance/)\n",
    "\n",
    "(Source could be set as \"Anywhere\" for AWS or \"0.0.0.0/0\" for GCP)\n",
    "\n",
    "To start Prefect Orion, [we could follow these steps by Kevin](https://discourse.prefect.io/t/hosting-an-orion-instance-on-a-cloud-vm/967):\n",
    "\n",
    "+ `pip install prefect==2.0b5` (Replace with most recent 2.0 version on pip)\n",
    "+ Set the PREFECT_ORION_UI_API_URL with :\n",
    "`prefect config set PREFECT_ORION_UI_API_URL=\"http://<external-ip>:4200/api\"`\n",
    "+ Start Orion:\n",
    "`prefect orion start --host 0.0.0.0`\n",
    "+ On the local machine, configure the API:\n",
    "`prefect config set PREFECT_API_URL=\"http://<external-ip>:4200/api\"`\n",
    "+ The remote UI will be visible on port 4200. Just type ```http://<external-ip>:4200```.  Example:  http://34.125.197.156:4200/\n",
    "\n",
    "\n",
    "You should see the variables being set with `prefect config view`.\n",
    "\n",
    "In case the prefect UI_API_URL or PREFECT_API_URL is already set to an older IP address, we can unset the variable by:\n",
    "```bash\n",
    "prefect config unset PREFECT_ORION_UI_API_URL\n",
    "```\n",
    "and then set the key as described above. (Replace PREFECT_ORION_UI_API_URL with PREFECT_API_URL for resetting PREFECT_API_URL)\n",
    "\n",
    "Now when running a script with Prefect Flow, the data should be logged into the remote VM Prefect instance.\n",
    "\n",
    "### Using Prefect Cloud <a name=\"cloud\"></a>\n",
    "\n",
    "Instead of running Prefect on a VM ourselves, we could use Prefect's Cloud service at https://beta.prefect.io which provides \n",
    "token login in addition to all other Prefect features.\n",
    "\n",
    "### Defining Storage for Prefect localy: <a name=\"storage-localy\"></a>\n",
    "\n",
    "In order to view the Prefect current configures storage we use `prefect storage ls`. By default, Prefect has no storage set and it stores results for runs in a temporary directory in its runtime environment. In order to create storage, we use `prefect storage create` then selecting the storage type we want if you choose ```Local Storage``` then you'll need to provide a path to storage the files, for example ```/home/username/.prefect```.\n",
    "\n",
    "### Defining Storage for Prefect in AWS S3: <a name=\"storage-aws\"></a>\n",
    "\n",
    "**Creating and Configuring AWS S3 Storage**:\n",
    "\n",
    "Free Tier Note: AWS S3 has 5GB free storage for free with somewhat limited read(GET) and more limited write(PUT) ops.\n",
    "\n",
    "First create an S3 Bucket; Search for S3 in the \"Services\" search bar and select \"S3\" (NOT \"S3 Glacier\").\n",
    "\n",
    "![S3](Images/Module3/S3.png)\n",
    "\n",
    "**Adding a User with S3 Permissions to AWS**:\n",
    "\n",
    "In order to access the S3 Bucket with Prefect, we need to add a new user with S3 Permissions:\n",
    "\n",
    "1 - Adding a User: To create the \"User\" which Prefect will use to access the S3 Bucket, we open the drop-down menu next to the account nameat the top right and select \"Security Credentials\" > \"Users\" (Left menu) > \"Add Users\".\n",
    "\n",
    "![Security Credentials](Images/Module3/security_credentials.png)\n",
    "\n",
    "![Users](Images/Module3/users.png)\n",
    "\n",
    "2 - Add a new user (ex: prefect) with an AWS Access Type of \"Programmatic Access\" and select \"Next:Permissions\".\n",
    "\n",
    "![Programmatic Access](Images/Module3/programmaticaccess.png)\n",
    "\n",
    "3 - We want to add a group with S3 Permissions and add our user to it; Select \"Create Group\" and name it (ex: S3-FullAccess) then in the policies search for \"S3FullAccess\" and select it (If you click on it, it redirects you to the policy details and you'll have to start over).\n",
    "\n",
    "![S3FullAccess](Images/Module3/S3FullAccess.png)\n",
    "\n",
    "4 - Select the new group and click \"Next:Tags\" (Put tags here if you want), then \"Next:Review\" then \"Create User\". Don't close this window! The Access Secret Key is irretrievable once lost!\n",
    "\n",
    "![Access Keys](Images/Module3/accesskeys.png)\n",
    "\n",
    "5 - Create new Prefect storage with `prefect storage create` and select Amazon S3.\n",
    "\n",
    "6 - Give the name of the S3 Bucket you've created beforehand.\n",
    "\n",
    "7 - Copy the access key from the User Window and paste it when prompted \"AWS ACCESS KEY ID\".\n",
    "\n",
    "8 - Copy the secret access key from the User Window and paste it when prompted \"AWS SECRET ACCESS KEY\".\n",
    "\n",
    "9 - Skip SESSION TOKEN, PROFILE NAME, REGION NAME (Press Enter).\n",
    "\n",
    "10 - Choose a \"Locally\" unique name for the configuration.\n",
    "\n",
    "11 - When prompted if you want to set it as default, select Y.\n",
    "\n",
    "Optional: Store the credentials in a CSV file.\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Deployment of Prefect flow <a name=\"deploy-prefect\"></a>\n",
    "\n",
    "[Video Source](https://www.youtube.com/watch?v=xw9JfaWPPps&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=24)\n",
    "\n",
    "### Deployment <a name=\"deploy\"></a>\n",
    "\n",
    "To store the run results, we have to modify our flow file; First we import:\n",
    "\n",
    "```python\n",
    "from prefect.deployments import DeploymentSpec\n",
    "from prefect.orion.schemas.schedules import IntervalSchedule\n",
    "from prefect.flow_runners import SubprocessFlowRunner\n",
    "from datetime import timedelta\n",
    "```\n",
    "Note that `SubprocessFlowRunner` is for non-containerized runs, if using Kubernetes or Docker we use something different.\n",
    "\n",
    "We then define a `DeploymentSpec`:\n",
    "```python\n",
    "DeploymentSpec(\n",
    "  flow=main,\n",
    "  name=\"momdel_training\",\n",
    "  schedule=IntervalSchedule(interval=timedelta(minutes=5)),\n",
    "  flow_runner=SubprocessFlowRunner(),\n",
    "  tags=[\"ml\"]\n",
    ")\n",
    "```\n",
    "`flow` is the flow to run. (Note `main` is no longer called explicitly)\n",
    "\n",
    "`schedule` is the schedule at which we run the flow. For example here every 5 minutes we run `main`.\n",
    "\n",
    "`tags` are tags associated with the flow. They can be used for filtering for example.\n",
    "\n",
    "`flow_runner` in this case specifies that the flow will only be ran locally; i.e: Not on Kubernetes or Docker containers.\n",
    "\n",
    "To create a deployment, we use:\n",
    "`prefect deployment create prefect_deploy.py` \n",
    "\n",
    "this only creates the deployment and schedules the runs. It does not know how to run them. To run them, we use Work Queues.\n",
    "\n",
    "\n",
    "### CronSchedule <a name=\"schedule\"></a>\n",
    "if you want to schedule to run for a certain day of a month you can't do that with ```IntervalSchedule``` you should use ```CronSchedule``` instead, example:\n",
    "\n",
    "\n",
    "```python\n",
    "from prefect.deployments import DeploymentSpec\n",
    "from prefect.orion.schemas.schedules import CronSchedule\n",
    "\n",
    "DeploymentSpec(\n",
    "    name=\"cron-schedule-deployment\",\n",
    "    flow_location=\"/path/to/flow.py\",\n",
    "    schedule=CronSchedule(\n",
    "        cron=\"0 0 * * *\",\n",
    "        timezone=\"America/New_York\"),\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "[Source](https://orion-docs.prefect.io/concepts/schedules/#cronschedule)\n",
    "\n",
    "you need to provide a cron string, with the next sintax:\n",
    "\n",
    "```bash\n",
    "┌───────────── minute (0 - 59)\n",
    "│ ┌───────────── hour (0 - 23)\n",
    "│ │ ┌───────────── day of the month (1 - 31)\n",
    "│ │ │ ┌───────────── month (1 - 12)\n",
    "│ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday;\n",
    "│ │ │ │ │                                   7 is also Sunday on some systems)\n",
    "│ │ │ │ │\n",
    "│ │ │ │ │\n",
    "* * * * * <command to execute>\n",
    "```\n",
    "\n",
    "Example Cron expression to run a flow at 9 AM every 15th of the month?\n",
    "\n",
    "```python \n",
    "\"0 9 15 * *\"\n",
    "``` \n",
    "\n",
    "[Source](https://en.wikipedia.org/wiki/Cron)\n",
    "\n",
    "\n",
    "### Work Queues <a name=\"queue\"></a>:\n",
    "\n",
    "The work queue a queue that will prompt its attached Agents to run the scheduled runs.\n",
    "\n",
    "To create a new work queue use the Prefect UI and select work queues in the side panel (A name is required for creating the queue), filtering by Tags is possible. A window will pop that includes the command used to add an agent to the work-queue; `prefect agent start <UUID>`. With the UUID being the UUID of the work-queue.\n",
    "\n",
    "We can check the state of the work-queue by using `prefect work-queue preview <UUID>` where it will show scheduled runs. \n",
    "\n",
    "#### Adding a Local Agent <a name=\"agent\"></a>\n",
    "\n",
    "Note: If the storage used is local, and the Agent is ran elsewhere it won't be able to get the files necessary for the run.\n",
    "\n",
    "The Agent is what runs the scheduled runs for the work-queue. It checks every 5 seconds whether there is work to do in the work-queue, fetches the flow file from storage and runs it.\n",
    "\n",
    "To run the agent we use the provided command on the local computer in the work-queue page:\n",
    "`prefect agent start <UUID>`\n",
    "\n",
    "[Back to the top](#)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## References <a name=\"references\"></a>\n",
    "\n",
    "https://github.com/ziritrion/mlopszoomcamp/blob/main/notes/1_intro.md\n",
    "\n",
    "https://github.com/LoHertel/Road-to-MLOps/blob/main/01-primer/README.md\n",
    "\n",
    "https://gist.github.com/Qfl3x/8dd69b8173f027b9468016c118f3b6a5\n",
    "\n",
    "\n",
    "https://cloud.google.com/compute/docs/connect/create-ssh-keys\n",
    "\n",
    "https://cloud.google.com/compute/docs/connect/add-ssh-keys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a8b40-5270-4641-b3b8-73f2e25da68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aa2ca-5bf5-40e1-a5c0-d80e5805204a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ae245-0282-42a7-8977-27f7598da28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010ec2e-93f8-436a-ba58-9440db04bb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54f8df-b37c-46c6-ae59-001595f2d8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6c9e1-3457-4f38-a5df-71ac99ad9fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56e9f9-efb8-47a6-af25-4fe459028b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b82c67-330c-4036-8e6f-01f692d89ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26eabbf1-ab57-4cfb-904f-1e077895b754",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a3808-e1e6-42d4-8f22-609169a3e74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4f90034-a628-4b65-9a4c-2f8553666f13",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Para las notas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1fd33-d325-4a9b-a5f3-88e2fcc2a984",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c34407-2351-41bd-993c-195e0ff984a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9b7fd-a154-4221-85b5-46a7943d4307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f8ee2-abe4-4fa8-b020-fe17d30ed0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196cc2c-2b25-41a4-bddc-88176fde227f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27a5db-726d-4a5c-94d5-e4a5f52c8fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f5727-2f46-4ce9-ac55-daf800d71530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c893d0e8-80a9-4bb1-bc30-9aaee0dbb258",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21fa1dc-3818-4d5f-93c0-74c975a0c1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d452311f-61b9-4666-b0ce-e0685fffc543",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9416caa4-2b75-4bf5-8202-8eb2fcea540d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6dc534-9053-41ec-8f1e-6a17ec248f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20899d49-2d74-4981-9bc3-7a0913a906ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
