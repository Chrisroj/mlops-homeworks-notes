# Table Of Contents

1. [Module 1: Introduction](#module1)

    1.1 [Introduction to MLOps](#intro)
    
    1.2 [Environment preparation](#environment)
    
      - 1.2.1 [VM Instance in AWS](#aws)
      
      - 1.2.1 [Install Dependencies](#dependencies)
      
    1.3 [Course Overview](#overview)
    
    1.4 [MLOps Maturity Model](#maturity)
    
    1.5 [Appendix](#appendix)
        
      - 1.5.1 [VM Instance in GCP](#gcp)
    
This notes are about [MLOps Zoomcamp](https://github.com/DataTalksClub/mlops-zoomcamp) module 1.

# Module 1: Introduction <a name="module1"></a>

[Source](https://github.com/DataTalksClub/mlops-zoomcamp/tree/main/01-intro)

## Introduction to MLOps <a name="intro"></a>

[Video source](https://youtu.be/s0uaFZSzwfI?list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK)

***MLOps*** is a _set of best practices_ for bringing Machine Learning to production.

Machine Learning projects can be simpplified to just 3 steps:

1. ***Design*** - is ML the right tool for solving our problem?
   * _We want to predict the duration of a taxi trip. Do we need to use ML or can we used a simpler rule-based model?_
2. ***Train*** - if we do need ML, then we train and evaluate the best model.
3. ***Operate*** - model deployment, management and monitoring.

MLOps is helpful in all 3 stages.

[Back to the top](#)


## Environment preparation <a name="environment"></a>

[Video source](https://www.youtube.com/watch?v=IXSiYkP23zo&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK)


You may check the link above to watch the video in order to learn how to set up a Linux VM instance in Amazon Web Services.
You can prepare your environment in your local machine too, but in our case we are going to set up a VM instance in GCP.


### VM Instance in AWS <a name="aws"></a>

You need to have an AWS account(if you want to do the same in GCP go to [VM Instance in GCP](#gcp))

1. **Create EC2 instance:**

    Go to EC2 service and click in launch instance(orange button), now config the VM as:
    - Name: `mlops-zoomcamp`
    - Amazon Machine Image: `Ubuntu Server 22.04 LTS (HVM), SSD Volume Type`
    - Architecture: `64-bit (x86)`
    - Instance type: `t2.large`    
    - Create and select a key pair:   
        - Key pair name: `asus-laptop`
        - Key pair type: `RSA`
        - Private key file format: `.pem`
    - Configure Storage: `1x 30 Gib gp2 Root Volume`
        


2. **Copy and paste `.pem` file:** 

    When you create a key pair a `.pem` will downloaded automatically, you will have to copy and paste this file to your  `~/.ssh` directory in your local machine.
    
    
3. **Connect to VM Instance:** 

    Go to `~./.ssh` directory and locate the `config` file type nano `~/.ssh/config` copy and paste:
    
    ```bash
    Host mlops-zoomcamp
        HostName EXTERNAL_IP
        User USER
        IdentityFile KEY_FILENAME_DIRECTORY
        LocalForward PORT_1 IP:PORT_1
        LocalForward PORT_2 IP:PORT_2
        LocalForward PORT_3 IP:PORT_3
    ```
    
    **Example:**

    ```bash
    Host mlops-zoomcamp
        HostName 18.117.147.165
        User ubuntu
        IdentityFile C:\Users\ferro\.ssh\asus-laptop.pem
        LocalForward 8888 localhost:8888
        LocalForward 5000 127.0.0.1:5000
        LocalForward 4200 0.0.0.0:4200
    ```
    
    
     
The EXTERNAL_IP can change every time you power one the VM. 
Now you can type `ssh mlops-zoomcamp` in your console and you'll get connected to the VM.

**Note0**: In step 4 in ```config``` file the last two lines are to forward multiple port through the same host, in this case 
```LocalForward 8888 localhost:8888``` is for jupyter, ```LocalForward 5000 127.0.0.1:5000``` is for MLflow and ```LocalForward 4200 0.0.0.0:4200``` is for Prefect. You can add more LocalForward if you want.

**Note1**: Don't forget to power off the VM after your work you can use ```sudo poweroff```. 

**Note2**: if you get the next warning:
```bash
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
```
Then copy and paste the EXTERNAL_IP of your VM and type:

```bash
ssh-keygen -R EXTERNAL_IP
```

Example:


```bash
ssh-keygen -R "34.125.105.3"
```

[Back to the top](#)

### Install Dependencies <a name="dependencies"></a>

Now we need to install the next dependencies(you can update the links for Anaconda and Docker Compose):

- **Install Anaconda**:

```bash
cd ~
wget https://repo.anaconda.com/archive/Anaconda3-2022.05-Linux-x86_64.sh
bash Anaconda3-2022.05-Linux-x86_64.sh
```

- **Install Docker**:

```bash
sudo apt update
sudo apt install docker.io
```

- **Install Docker Compose**

```bash
mkdir soft
cd soft/
wget https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-linux-x86_64 -O docker-compose
chmod +x docker-compose
```

- **Modified PATH Varibles**


   Type ```nano .bashrc```, copy and paste the next at the end of the `.bashrc` file

```bash
export PATH="${HOME}/soft:${PATH}"
```

Type `source .bashrc`, now everything that is in `/soft` directory will be in the PATH then you can execute it everywhere.

- **Add current user to docker group**

```bash
sudo usermod -aG docker $USER
logout
```

Then logback to the VM.

- **Verify Installation**

```bash
which python
# /home/w10/anaconda3/bin/python

which docker
# /usr/bin/docker

which docker-compose
# /home/w10/soft/docker-compose

docker run hello-world
```

- **Run Jupyter Notebook**

```bash
jupyter notebook
```

[Back to the top](#)


## Course Overview <a name="overview"></a>

[Video source](https://www.youtube.com/watch?v=teP9KWkP6SM&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=6)

When data scientists experiment with Jupyter Notebooks for creating models, they often don't follow best practices and are often unstructured due to the nature of experimentation: cells are re-run with slightly different values and previous results may be lost, or the cell execution order may be inconsistent, for example.

***Module 2*** covers ***experiment tracking***: by using tools such as [MLflow](https://mlflow.org/) we will create ***experiment trackers*** (such as the history of cells that we've rerun multiple times) and ***model registries*** (for storing the models we've created during the experiments), instead of relying on our memory or janky setups such as external spreadsheets or convoluted naming schemes for our files.

***Module 3*** covers ***orchestration and ML pipelines***: by using tools such as [Prefect](https://www.prefect.io/) and [Kubeflow](https://www.kubeflow.org/) we can break down our notebooks into separate identifyable steps and connect them in order to create a ***ML pipeline*** which we can parametrize with the data and models we want and easily execute.

![asda](./Images/Module1/ML-pipeline.PNG)

***Module 4*** covers ***serving the models***: we will learn how to deploy models in different ways.

***Module 5*** covers ***model monitoring***: we will see how to check whether our model is performing fine or not and how to generate alers to warn us of performance drops and failures, and even automate retraining and redeploying models without human input.

***Module 6*** covers ***best practices***, such as how to properly maintain and package code, how to deploy successfully, etc.

***Module 7*** covers ***processes***: we will see how to properly communicate between all the stakeholders of a ML project (scientists, engineers, etc) and how to work together.

[Back to the top](#)


## MLOps Maturity Model <a name="maturity"></a>

[Video Source](https://www.youtube.com/watch?v=XwTH8BDGzYk&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=7)

[Table Source](https://docs.microsoft.com/en-us/azure/architecture/example-scenario/mlops/mlops-maturity-model)

A framework for classifying different levels of MLOps maturity is listed below:


| Lvl |              | Overview | Use Case | 
|----:|--------------|----------|----------|  
| 0️⃣  | **No MLOps** | <ul><li>ML process highly manual</li><li>poor cooperation</li><li>lack of standards, success depends on an individual's expertise</li> </ul> | <ul><li>proof of concept (PoC)</li><li>academic project</li></ul> |
| 1️⃣  | **DevOps but no MLOps** | <ul><li>ML training is most often manual </li><li>software engineers might help with the deployment</li><li>automated tests and releases</li> </ul> | <ul><li>bringing PoC to production</li></ul> |
| 2️⃣  | **Automated Training** | <ul><li>ML experiment results are centrally tracked </li><li>training code and models are version controlled</li><li>deployment is handled by software engineers</li> </ul> | <ul><li>maintaining 2-3+ ML models</li></ul> |
| 3️⃣  | **Automated Model Deployment** | <ul><li>releases are managed by an automated CI/CD pipeline</li><li>close cooperation between data and software engineers</li><li>performance of the deployed model is monitored, A/B tests for model selection are used</li></ul> | <ul><li>business-critical ML services</li></ul> |
| 4️⃣  | **Full MLOps Automated Operations** | <ul><li>clearly defined metrics for model monitoring</li><li>automatic retraining triggered when passing a model metric's threshold</li> </ul>  | <ul><li>use only when a favorable trade-off between implementation cost and increase in efficiency is likely</li><li>retraining is needed often and is repetitive (has potential for automation)</li></ul> |

Be aware that not every project or even every part of a project needs to have the highest maturity level possible because it could exceed the project's resource budget. **Pragmatism is key**.


[Back to the top](#)

## Appendix <a name="appendix"></a>

### VM Instance in GCP <a name="gcp"></a>


Before to create an instance in GCP we need to generate a SSH key(if you want to know what SSH is you can check this [video](https://www.youtube.com/watch?v=RMS5zBYQIqA)). In your local console(in my case in Git Bash in windows) follow:

You can watch this [video](https://www.youtube.com/watch?v=ae-CV2KfoN0) or follow the next instructions.

1. **Create SSH keys:**

    Create(if you don't have) and go to ```~/.ssh``` directory and type:

```bash
ssh-keygen -t rsa -f KEY_FILENAME -C USER -b 2048
```
    Example:

```bash
ssh-keygen -t rsa -f gcp_ssh -C w10 -b 2048
```

[Source](https://cloud.google.com/compute/docs/connect/create-ssh-keys)

2. **Put this SSH key in GCP:**
    
    1. Copy public key:
    
        ```bash
        cat KEY_FILENAME.pub
        ```
        Example:
        ```bash
        cat gcp_ssh.pub
        ```
    2. In Cloud console go to **Metadata** -> **EDIT** -> **SSH keys** -> **Add item** -> **Paste public key** -> **Save**
    
_[Source](https://cloud.google.com/compute/docs/connect/add-ssh-keys)_
    
3. **Create VM Instance:**

    In Cloud console go to **Compute Engine** -> **VM Instances** -> **Create Instance** config the VM as:
    * name: `mlops-zoomcamp-vm`
    * region: `us-west4 (Las Vegas)`, zone: `us-west4-b`
    * serie: `E2`, type: `e2-standard-4`
    * boot disk image: `Ubuntu 22.04 LTS` boot disk type: `balanced persistent disk` size(gb): `30`
    
4. **Connect to VM Instance:** 

    Go to ```~./.ssh``` directory and locate the ```config``` type ```nano ~/.ssh/config```copy and paste:

```bash
Host mlops-zoomcamp-vm
    HostName EXTERNAL_IP
    User USER
    IdentityFile KEY_FILENAME_DIRECTORY
    LocalForward PORT_1 IP:PORT_1
    LocalForward PORT_2 IP:PORT_2
    LocalForward PORT_3 IP:PORT_3
```
  
    Example:

```bash
Host mlops-zoomcamp-vm
    HostName 34.125.197.156
    User w10
    IdentityFile C:\Users\w10\.ssh\gcp_ssh
    LocalForward 8888 localhost:8888
    LocalForward 5000 127.0.0.1:5000
    LocalForward 4200 0.0.0.0:4200
```


    The EXTERNAL_IP can change every time you power one the VM. 
Now you can type `ssh mlops-zoomcamp-vm` in your console and you'll get connected to the VM.

**Note0**: In step 4 in ```config``` file the last two lines are to forward multiple port through the same host, in this case 
```LocalForward 8888 localhost:8888``` is for jupyter, ```LocalForward 5000 127.0.0.1:5000``` is for MLflow and ```LocalForward 4200 0.0.0.0:4200``` is for Prefect. You can add more LocalForward if you want.

**Note1**: Don't forget to power off the VM after your work you can use ```sudo poweroff```. 

**Note2**: if you get the next warning:
```bash
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
```
Then copy and paste the EXTERNAL_IP of your VM and type:

```bash
ssh-keygen -R "34.125.105.3"
```

[Back to the top](#)


## Sources 
- https://github.com/ziritrion/mlopszoomcamp/blob/main/notes/1_intro.md
- https://github.com/LoHertel/Road-to-MLOps/blob/main/01-primer/README.md
- https://cloud.google.com/compute/docs/connect/create-ssh-keys
- https://cloud.google.com/compute/docs/connect/add-ssh-keys